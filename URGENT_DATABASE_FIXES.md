# ğŸš¨ URGENT: Database Connection Issues - Root Cause & Fixes

## Problem Identified

Your Cloud SQL instance is **critically undersized** for production:

### Current Configuration
- **Instance Type:** `db-f1-micro` âš ï¸
- **RAM:** 0.6 GB (too small!)
- **CPU:** Shared (not dedicated)
- **Max Connections:** ~25-50
- **Disk:** 10 GB

### Why This Causes 500 Errors

1. **Connection Exhaustion:**
   - App tries to use up to 30 connections
   - Database can only handle ~25-50 total
   - Connections get rejected or corrupted
   - Results in errors like: `error with status PGRES_TUPLES_OK`

2. **Memory Pressure:**
   - 0.6 GB RAM is insufficient for even moderate workloads
   - Database runs out of memory
   - Connections get terminated unexpectedly
   - SQLAlchemy can't recover: `ResourceClosedError: This result object does not return rows`

3. **Shared CPU:**
   - CPU time is shared with other Google Cloud customers
   - Unpredictable performance
   - Queries time out randomly
   - Connections go stale

---

## âœ… Fixes Implemented (Deploy 144)

### 1. Aggressive Connection Pool Settings âœ…

```python
SQLALCHEMY_ENGINE_OPTIONS = {
    'pool_size': 5,  # Reduced to avoid exhausting database
    'max_overflow': 10,  # Total 15 connections max
    'pool_recycle': 300,  # Recycle every 5 minutes (aggressive)
    'pool_pre_ping': True,  # Always test before use
    'pool_reset_on_return': 'rollback',  # Always rollback
    'pool_timeout': 10,  # Fail fast
    'pool_use_lifo': True  # Keep connections warm
}
```

### 2. Global Error Handling âœ…

```python
@app.teardown_appcontext
def shutdown_session(exception=None):
    if exception:
        db.session.rollback()
        db.engine.dispose()  # Force clear bad connections
    db.session.remove()

@app.errorhandler(Exception)
def handle_exception(e):
    db.session.rollback()
    db.engine.dispose()  # Nuclear option: dispose all connections
    return error_response
```

### 3. Query Timeouts âœ…

- Statement timeout: 10 seconds (was 30)
- Connection timeout: 5 seconds
- Faster keepalives: every 5 seconds

---

## ğŸ”§ REQUIRED: Upgrade Database Instance

### Recommended Minimum for Production

```bash
# Option 1: Small Production Instance (Recommended)
gcloud sql instances patch capturecare-db \
    --tier=db-g1-small \
    --project=capturecare-461801

# Cost: ~$25/month
# RAM: 1.7 GB
# CPU: 1 shared vCPU
# Max Connections: ~100
```

### Better Option for Stability

```bash
# Option 2: Custom Instance with Dedicated CPU
gcloud sql instances patch capturecare-db \
    --tier=db-custom-2-7680 \
    --project=capturecare-461801

# Cost: ~$100/month
# RAM: 7.5 GB
# CPU: 2 dedicated vCPUs
# Max Connections: ~500
```

### Why Upgrade?

| Metric | db-f1-micro (Current) | db-g1-small | db-custom-2-7680 |
|--------|----------------------|-------------|------------------|
| **RAM** | 0.6 GB âš ï¸ | 1.7 GB âœ… | 7.5 GB âœ…âœ… |
| **CPU** | Shared âš ï¸ | Shared âœ… | Dedicated âœ…âœ… |
| **Max Connections** | ~25 âš ï¸ | ~100 âœ… | ~500 âœ…âœ… |
| **Cost/month** | ~$10 | ~$25 | ~$100 |
| **Suitable for** | Testing only | Small prod | Production |

---

## ğŸ“Š Immediate Testing

### After Upgrade, Test:

1. **Patient Page** 
   - Navigate to: https://capturecare-310697189983.australia-southeast2.run.app/patients/1
   - All sections should load without 500 errors:
     - âœ… Appointments
     - âœ… Notes
     - âœ… Heart rate charts
     - âœ… Health data

2. **Multiple Concurrent Users**
   - Open 5 browser tabs
   - Navigate to different pages in each
   - Should not see connection errors

3. **Monitor Logs**
   ```bash
   gcloud logging read 'severity>=ERROR AND resource.labels.service_name=capturecare' \
       --limit=20 --project=capturecare-461801
   ```
   - Should see NO `psycopg2` errors
   - Should see NO `ResourceClosedError`

---

## âš¡ Quick Upgrade Instructions

### 1. Upgrade Database (5 minutes)

```bash
# This is SAFE - no downtime for Cloud SQL
gcloud sql instances patch capturecare-db \
    --tier=db-g1-small \
    --project=capturecare-461801
```

This will:
- âœ… Upgrade RAM from 0.6 GB â†’ 1.7 GB
- âœ… Improve connection capacity
- âœ… Take ~2-3 minutes
- âœ… No data loss
- âš ï¸ Brief connection interruption (a few seconds)

### 2. Monitor Results

After upgrade completes:

```bash
# Check new configuration
gcloud sql instances describe capturecare-db \
    --project=capturecare-461801 \
    --format="value(settings.tier)"
```

Should show: `db-g1-small`

### 3. Test Application

Visit: https://capturecare-310697189983.australia-southeast2.run.app/patients/1

All sections should load without errors.

---

## ğŸ¯ Expected Outcomes

### Before Upgrade (Current State)
- âŒ Random 500 errors on patient pages
- âŒ Appointments fail to load
- âŒ Notes fail to load
- âŒ Heart rate charts fail to load
- âŒ Errors: "lost synchronization with server"
- âŒ Errors: "ResourceClosedError"

### After Upgrade + Deployed Fixes
- âœ… All pages load reliably
- âœ… No connection corruption
- âœ… No random 500 errors
- âœ… Stable under concurrent load
- âœ… Fast query execution
- âœ… Proper error recovery

---

## ğŸ’° Cost Analysis

### Current Costs
- Cloud Run: ~$5-10/month
- Cloud SQL (db-f1-micro): ~$10/month
- **Total: ~$15-20/month**

### After Upgrade to db-g1-small
- Cloud Run: ~$5-10/month
- Cloud SQL (db-g1-small): ~$25/month
- **Total: ~$30-35/month**

### After Upgrade to db-custom-2-7680 (Recommended for Growth)
- Cloud Run: ~$5-10/month
- Cloud SQL (db-custom-2-7680): ~$100/month
- **Total: ~$105-110/month**

**Recommendation:** Start with `db-g1-small` ($25/month) and upgrade to custom tier if you hit limits.

---

## ğŸš¨ Priority Actions

### IMMEDIATE (Do Now)
1. âœ… Deploy 144 already deployed (aggressive connection handling)
2. âš ï¸ **UPGRADE DATABASE TO db-g1-small** (5 min, $15/month more)
3. âœ… Test patient page after upgrade

### SHORT TERM (This Week)
1. Monitor error logs for 24-48 hours
2. If still seeing issues, upgrade to db-custom-2-7680
3. Add Christmas/New Year company-wide closure dates

### LONG TERM (This Month)
1. Set up database monitoring/alerts
2. Consider read replicas if traffic grows
3. Implement query optimization
4. Add application-level caching (Redis)

---

## ğŸ“ Support Commands

### Check Current Instance Size
```bash
gcloud sql instances describe capturecare-db \
    --project=capturecare-461801 \
    --format="value(settings.tier)"
```

### Upgrade Database (Recommended)
```bash
gcloud sql instances patch capturecare-db \
    --tier=db-g1-small \
    --project=capturecare-461801
```

### Check Connection Count
```bash
gcloud sql operations list \
    --instance=capturecare-db \
    --project=capturecare-461801 \
    --limit=5
```

### Monitor Error Logs
```bash
gcloud logging read 'severity>=ERROR AND resource.labels.service_name=capturecare' \
    --limit=20 --project=capturecare-461801 --format=json
```

---

## âœ… Success Checklist

After completing the upgrade and testing:

- [ ] Database upgraded to at least db-g1-small
- [ ] Patient page loads without 500 errors
- [ ] Appointments section loads
- [ ] Notes section loads
- [ ] Heart rate charts load
- [ ] No errors in logs for 1 hour
- [ ] Multiple tabs work simultaneously
- [ ] Added Christmas closure in Company Settings

---

## ğŸ‰ Final Status

**Current Deploy:** Revision 144 (capturecare-00144-gg7)
**Status:** âœ… Code fixes deployed
**Blocking Issue:** âš ï¸ Database instance too small

**Next Step:** Run the upgrade command above (5 minutes, $15/month additional cost)

Once upgraded, your application should be stable and performant! ğŸš€

